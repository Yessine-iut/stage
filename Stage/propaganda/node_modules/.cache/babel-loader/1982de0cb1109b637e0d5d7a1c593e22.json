{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\dofla\\\\Desktop\\\\Stage\\\\propaganda\\\\src\\\\pages\\\\about.js\";\n//import { Link} from \"react-router-dom\";\n//import Button from '../components/button';\n//import ProductHero from '../components/productHero.js';\nimport Propaganda from \"../images/propaganda.png\";\nimport \"../styles/about.css\";\nimport Button from '../components/button';\nimport Card from '../components/card2';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\n\nconst About = () => {\n  return /*#__PURE__*/_jsxDEV(_Fragment, {\n    children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n      id: \"h1\",\n      children: \"About\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 17,\n      columnNumber: 4\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"One of the mechanisms through which disinformation is spreading online, in particular through social media, is by employing propaganda techniques. These include specific rhetorical and psychological strategies, ranging from leveraging on emotions to exploiting logical fallacies. We adopt a supervised approach (i.e., BERT and RoBERTa Transformer-based models) to classify textual snippets both as propaganda messages and according to the precise applied propaganda technique, as well as a detailed linguistic analysis of the features characterising propaganda information in text (e.g., semantic, sentiment and argumentation features). \"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 18,\n      columnNumber: 4\n    }, this)]\n  }, void 0, true);\n};\n\n_c = About;\nexport default About;\n\nvar _c;\n\n$RefreshReg$(_c, \"About\");","map":{"version":3,"sources":["C:/Users/dofla/Desktop/Stage/propaganda/src/pages/about.js"],"names":["Propaganda","Button","Card","About"],"mappings":";AAAA;AACA;AACA;AAEA,OAAOA,UAAP,MAAuB,0BAAvB;AACA,OAAO,qBAAP;AAEA,OAAOC,MAAP,MAAmB,sBAAnB;AACA,OAAOC,IAAP,MAAiB,qBAAjB;;;;AAKA,MAAMC,KAAK,GAAG,MAAM;AAChB,sBACA;AAAA,4BACD;AAAI,MAAA,EAAE,EAAC,IAAP;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YADC,eAED;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAFC;AAAA,kBADA;AAKD,CANH;;KAAMA,K;AAQJ,eAAeA,KAAf","sourcesContent":["//import { Link} from \"react-router-dom\";\r\n//import Button from '../components/button';\r\n//import ProductHero from '../components/productHero.js';\r\n\r\nimport Propaganda from \"../images/propaganda.png\";\r\nimport \"../styles/about.css\";\r\n\r\nimport Button from '../components/button';\r\nimport Card from '../components/card2';\r\n\r\n\r\n\r\n\r\nconst About = () => {\r\n    return (\r\n    <>\r\n   <h1 id='h1'>About</h1>\r\n   <p>One of the mechanisms through which disinformation is spreading online, in particular through social media, is by employing propaganda techniques. These include specific rhetorical and psychological strategies, ranging from leveraging on emotions to exploiting logical fallacies. We adopt a supervised approach (i.e., BERT and RoBERTa Transformer-based models) to classify textual snippets both as propaganda messages and according to the precise applied propaganda technique, as well as a detailed linguistic analysis of the features characterising propaganda information in text (e.g., semantic, sentiment and argumentation features). </p>\r\n    </>);\r\n  };\r\n  \r\n  export default About;"]},"metadata":{},"sourceType":"module"}